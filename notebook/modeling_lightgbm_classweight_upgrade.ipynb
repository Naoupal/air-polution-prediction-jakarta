{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM Air Quality Forecasting Model\n",
    "## Jakarta ISPU Prediction (2022-2025)\n",
    "\n",
    "This notebook implements a **LightGBM classifier with class_weight** for predicting air quality categories in Jakarta using:\n",
    "- **Lag Features**: Previous day and weekly pollution levels\n",
    "- **Weather Features**: Temperature, precipitation, wind\n",
    "- **Class Weighting**: To handle severe class imbalance\n",
    "- **Time-based Split**: To prevent data leakage\n",
    "\n",
    "### Key Improvements:\n",
    "1. ‚úÖ **LightGBM** instead of XGBoost (faster, better with imbalanced data)\n",
    "2. ‚úÖ **class_weight** parameter for handling imbalance\n",
    "3. ‚úÖ **Strict temporal split** (no data leakage)\n",
    "4. ‚úÖ **Better feature selection** (only past information)\n",
    "5. ‚úÖ **Categorical feature support** (native in LightGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 1: Import Libraries\n",
    "# =============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# LightGBM\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, \n",
    "    accuracy_score, f1_score, precision_score, recall_score,\n",
    "    balanced_accuracy_score\n",
    ")\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Configuration\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "print(\"‚úì Libraries imported successfully\")\n",
    "print(f\"  LightGBM version: {lgb.__version__}\")\n",
    "print(f\"  Pandas version: {pd.__version__}\")\n",
    "print(f\"  NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Load Data and Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 2: Load Preprocessed Data\n",
    "# =============================================================================\n",
    "\n",
    "# Load the preprocessed master dataframe (unscaled - tree models don't need scaling)\n",
    "df = pd.read_csv(\"/mnt/user-data/uploads/master_df_unscaled.csv\", parse_dates=['tanggal'])\n",
    "\n",
    "print(f\"‚úì Data loaded: {df.shape[0]:,} records √ó {df.shape[1]} features\")\n",
    "print(f\"  Date range: {df['tanggal'].min().date()} to {df['tanggal'].max().date()}\")\n",
    "print(f\"  Stations: {sorted(df['stasiun_id'].unique())}\")\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(df.head())\n",
    "\n",
    "# Check target distribution\n",
    "print(f\"\\nüìä Target Variable Distribution (kategori_encoded):\")\n",
    "target_counts = df['kategori_encoded'].value_counts().sort_index()\n",
    "category_names = {\n",
    "    -1: 'UNKNOWN', \n",
    "    0: 'BAIK', \n",
    "    1: 'SEDANG', \n",
    "    2: 'TIDAK SEHAT', \n",
    "    3: 'SANGAT TIDAK SEHAT', \n",
    "    4: 'BERBAHAYA'\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "for val, count in target_counts.items():\n",
    "    name = category_names.get(int(val), 'UNKNOWN')\n",
    "    pct = count/len(df)*100\n",
    "    bar = '‚ñà' * int(pct / 2)\n",
    "    print(f\"   {name:20s} ({int(val):2d}): {count:6,} ({pct:5.1f}%) {bar}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check imbalance ratio\n",
    "max_count = target_counts.max()\n",
    "min_count = target_counts[target_counts > 0].min()\n",
    "imbalance_ratio = max_count / min_count\n",
    "print(f\"\\n‚ö†Ô∏è Imbalance Ratio: {imbalance_ratio:.1f}:1\")\n",
    "print(f\"   Majority class: {max_count:,} samples\")\n",
    "print(f\"   Minority class: {min_count:,} samples\")\n",
    "print(f\"   ‚Üí Severe imbalance! Will use class_weight to handle this.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Feature Selection - Prevent Data Leakage\n",
    "\n",
    "### ‚ö†Ô∏è CRITICAL: Data Leakage Prevention\n",
    "\n",
    "In time-series forecasting, **data leakage** occurs when information from the future is used to predict the past. To prevent this:\n",
    "\n",
    "**MUST DROP:**\n",
    "1. ‚ùå Same-day pollutant measurements (pm_sepuluh, pm_duakomalima, etc.) - these are what we're predicting!\n",
    "2. ‚ùå Identifiers (tanggal, stasiun_id, stasiun) - not useful for prediction\n",
    "3. ‚ùå Target variable derivatives (kategori, parameter_pencemar_kritis)\n",
    "\n",
    "**SAFE TO KEEP:**\n",
    "1. ‚úÖ Lag features (lag_1, lag_7, etc.) - past values available at prediction time\n",
    "2. ‚úÖ Rolling features - computed from past values only\n",
    "3. ‚úÖ Weather features - external data available at prediction time\n",
    "4. ‚úÖ Time features (year, month, is_weekend) - known at prediction time\n",
    "5. ‚úÖ Static features (NDVI, population) - slowly changing, safe to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 3: Feature Selection - Prevent Data Leakage\n",
    "# =============================================================================\n",
    "\n",
    "# Define columns to DROP to prevent leakage\n",
    "COLUMNS_TO_DROP = [\n",
    "    # ‚ùå Identifiers (not useful for prediction)\n",
    "    'tanggal', 'stasiun_id', 'stasiun',\n",
    "    \n",
    "    # ‚ùå Same-day pollutants (SEVERE LEAKAGE!)\n",
    "    # These are what we're trying to predict, so they CANNOT be used as features\n",
    "    'pm_sepuluh', 'pm_duakomalima', 'sulfur_dioksida', \n",
    "    'karbon_monoksida', 'ozon', 'nitrogen_dioksida', 'max',\n",
    "    \n",
    "    # ‚ùå Categorical target and related columns\n",
    "    'kategori', 'parameter_pencemar_kritis',\n",
    "    \n",
    "    # ‚ùå Target variable (will be assigned to y)\n",
    "    'kategori_encoded'\n",
    "]\n",
    "\n",
    "# Get feature columns (everything except dropped columns)\n",
    "feature_cols = [col for col in df.columns if col not in COLUMNS_TO_DROP]\n",
    "\n",
    "print(\"üìã FEATURE SELECTION SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\n‚ùå Columns DROPPED ({len(COLUMNS_TO_DROP)}):\")\n",
    "for i, col in enumerate(COLUMNS_TO_DROP, 1):\n",
    "    if col in df.columns:\n",
    "        print(f\"   {i:2d}. {col}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Features KEPT ({len(feature_cols)}):\")\n",
    "\n",
    "# Categorize features for better understanding\n",
    "feature_categories = {\n",
    "    'üïê Lag Features': [c for c in feature_cols if 'lag' in c.lower() and 'rolling' not in c.lower()],\n",
    "    'üìà Rolling Features': [c for c in feature_cols if 'rolling' in c.lower()],\n",
    "    'üå°Ô∏è Temperature': [c for c in feature_cols if 'temp' in c.lower()],\n",
    "    'üí® Wind': [c for c in feature_cols if 'wind' in c.lower()],\n",
    "    'üåßÔ∏è Precipitation': [c for c in feature_cols if 'precipitation' in c.lower()],\n",
    "    'üíß Humidity': [c for c in feature_cols if 'humidity' in c.lower()],\n",
    "    'üå°Ô∏è Pressure': [c for c in feature_cols if 'pressure' in c.lower()],\n",
    "    '‚òÅÔ∏è Cloud': [c for c in feature_cols if 'cloud' in c.lower()],\n",
    "    '‚òÄÔ∏è Radiation': [c for c in feature_cols if 'radiation' in c.lower()],\n",
    "    'üìÖ Time Features': [c for c in feature_cols if c in ['year', 'month', 'is_weekend', 'is_holiday_nasional']],\n",
    "    'üåä River Quality': [c for c in feature_cols if c in ['pH', 'BOD', 'COD', 'DO', 'TSS']],\n",
    "    'üåø Environmental': [c for c in feature_cols if c in ['ndvi', 'jumlah_penduduk']],\n",
    "}\n",
    "\n",
    "print()\n",
    "total_categorized = 0\n",
    "for category, features in feature_categories.items():\n",
    "    if features:\n",
    "        print(f\"   {category} ({len(features)}):\")\n",
    "        if len(features) <= 5:\n",
    "            print(f\"      {features}\")\n",
    "        else:\n",
    "            print(f\"      {features[:3]} ... and {len(features)-3} more\")\n",
    "        total_categorized += len(features)\n",
    "\n",
    "# Check for uncategorized features\n",
    "categorized_features = [f for cat in feature_categories.values() for f in cat]\n",
    "uncategorized = [f for f in feature_cols if f not in categorized_features]\n",
    "if uncategorized:\n",
    "    print(f\"\\n   ‚ùì Uncategorized Features ({len(uncategorized)}):\")\n",
    "    print(f\"      {uncategorized}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(f\"Total features: {len(feature_cols)}\")\n",
    "print(f\"Categorized: {total_categorized}, Uncategorized: {len(uncategorized)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Time-Based Train/Test Split\n",
    "\n",
    "### ‚è∞ Temporal Split Strategy\n",
    "\n",
    "For time-series forecasting, we **MUST** use temporal splits:\n",
    "- **Training**: 2022-2024 (historical data)\n",
    "- **Test**: 2025 (future data we want to predict)\n",
    "\n",
    "**Why NOT random split?**\n",
    "- ‚ùå Random split causes **temporal leakage** (using future to predict past)\n",
    "- ‚ùå Doesn't reflect real-world scenario\n",
    "- ‚ùå Inflates model performance artificially\n",
    "\n",
    "**Why temporal split?**\n",
    "- ‚úÖ Simulates real forecasting scenario\n",
    "- ‚úÖ Prevents temporal leakage\n",
    "- ‚úÖ Gives realistic performance estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 4: Prepare Features and Handle Missing Values\n",
    "# =============================================================================\n",
    "\n",
    "# Prepare X (features) and y (target)\n",
    "X = df[feature_cols].copy()\n",
    "y = df['kategori_encoded'].copy()\n",
    "dates = df['tanggal'].copy()\n",
    "\n",
    "# Convert all feature columns to numeric\n",
    "print(\"üîÑ Converting features to numeric...\")\n",
    "for col in feature_cols:\n",
    "    X[col] = pd.to_numeric(X[col], errors='coerce')\n",
    "\n",
    "# Analyze missing values\n",
    "print(\"\\nüìä Missing Values Analysis:\")\n",
    "missing_summary = []\n",
    "for col in feature_cols:\n",
    "    missing = X[col].isna().sum()\n",
    "    if missing > 0:\n",
    "        missing_summary.append((col, missing, missing/len(X)*100))\n",
    "\n",
    "if missing_summary:\n",
    "    print(f\"\\n   Found {len(missing_summary)} features with missing values:\")\n",
    "    for col, missing, pct in sorted(missing_summary, key=lambda x: -x[1])[:15]:\n",
    "        print(f\"      ‚Ä¢ {col:40s}: {missing:6,} missing ({pct:5.1f}%)\")\n",
    "else:\n",
    "    print(\"   ‚úì No missing values found!\")\n",
    "\n",
    "# Handle missing values strategically\n",
    "print(\"\\nüîß Handling Missing Values:\")\n",
    "\n",
    "# Strategy 1: Fill lag features with -1 (indicates \"no prior data\")\n",
    "lag_cols = [c for c in feature_cols if 'lag' in c.lower()]\n",
    "for col in lag_cols:\n",
    "    if X[col].isna().any():\n",
    "        X[col] = X[col].fillna(-1)\n",
    "print(f\"   ‚úì Filled {len(lag_cols)} lag features with -1 (no prior data)\")\n",
    "\n",
    "# Strategy 2: Fill rolling features with 0 (indicates no history)\n",
    "rolling_cols = [c for c in feature_cols if 'rolling' in c.lower()]\n",
    "for col in rolling_cols:\n",
    "    if X[col].isna().any():\n",
    "        X[col] = X[col].fillna(0)\n",
    "if rolling_cols:\n",
    "    print(f\"   ‚úì Filled {len(rolling_cols)} rolling features with 0 (no history)\")\n",
    "\n",
    "# Strategy 3: Fill remaining features with median (safe for tree models)\n",
    "remaining_missing = []\n",
    "for col in feature_cols:\n",
    "    if X[col].isna().any():\n",
    "        median_val = X[col].median()\n",
    "        X[col] = X[col].fillna(median_val)\n",
    "        remaining_missing.append((col, median_val))\n",
    "\n",
    "if remaining_missing:\n",
    "    print(f\"   ‚úì Filled {len(remaining_missing)} features with median:\")\n",
    "    for col, median in remaining_missing[:5]:\n",
    "        print(f\"      ‚Ä¢ {col}: median = {median:.2f}\")\n",
    "    if len(remaining_missing) > 5:\n",
    "        print(f\"      ... and {len(remaining_missing)-5} more\")\n",
    "\n",
    "# Verify no missing values remain\n",
    "assert X.isna().sum().sum() == 0, \"‚ùå Still have missing values!\"\n",
    "print(f\"\\n‚úÖ All missing values handled successfully\")\n",
    "\n",
    "# Remove invalid target values (-1 = UNKNOWN)\n",
    "valid_mask = (y >= 0)\n",
    "X = X[valid_mask]\n",
    "y = y[valid_mask]\n",
    "dates = dates[valid_mask]\n",
    "\n",
    "print(f\"\\nüìä Data after cleaning:\")\n",
    "print(f\"   Total records: {len(X):,}\")\n",
    "print(f\"   Total features: {len(feature_cols)}\")\n",
    "print(f\"\\n   Target distribution:\")\n",
    "for val in sorted(y.unique()):\n",
    "    count = (y == val).sum()\n",
    "    print(f\"      Class {int(val):2d}: {count:6,} ({count/len(y)*100:5.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 5: Time-Based Train/Test Split\n",
    "# =============================================================================\n",
    "\n",
    "# Extract year for temporal splitting\n",
    "years = dates.dt.year\n",
    "\n",
    "# Create temporal masks\n",
    "train_mask = years < 2025\n",
    "test_mask = years >= 2025\n",
    "\n",
    "# Split data\n",
    "X_train = X[train_mask].reset_index(drop=True)\n",
    "X_test = X[test_mask].reset_index(drop=True)\n",
    "y_train = y[train_mask].reset_index(drop=True)\n",
    "y_test = y[test_mask].reset_index(drop=True)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"‚è∞ TIME-BASED TRAIN/TEST SPLIT\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nüìÖ Training Set (2022-2024): {len(X_train):,} records\")\n",
    "print(f\"üìÖ Test Set (2025):          {len(X_test):,} records\")\n",
    "print(f\"\\n   Split ratio: {len(X_train)/(len(X_train)+len(X_test))*100:.1f}% train, {len(X_test)/(len(X_train)+len(X_test))*100:.1f}% test\")\n",
    "\n",
    "# Show class distribution in train set\n",
    "print(f\"\\nüìä Training Set - Class Distribution:\")\n",
    "print(\"   \" + \"=\"*60)\n",
    "train_counts = y_train.value_counts().sort_index()\n",
    "for val in sorted(y_train.unique()):\n",
    "    count = (y_train == val).sum()\n",
    "    pct = count/len(y_train)*100\n",
    "    bar = '‚ñà' * int(pct / 2)\n",
    "    print(f\"   Class {int(val):2d}: {count:6,} ({pct:5.1f}%) {bar}\")\n",
    "print(\"   \" + \"=\"*60)\n",
    "\n",
    "# Show class distribution in test set\n",
    "print(f\"\\nüìä Test Set - Class Distribution:\")\n",
    "print(\"   \" + \"=\"*60)\n",
    "test_counts = y_test.value_counts().sort_index()\n",
    "for val in sorted(y_test.unique()):\n",
    "    count = (y_test == val).sum()\n",
    "    pct = count/len(y_test)*100\n",
    "    bar = '‚ñà' * int(pct / 2)\n",
    "    print(f\"   Class {int(val):2d}: {count:6,} ({pct:5.1f}%) {bar}\")\n",
    "print(\"   \" + \"=\"*60)\n",
    "\n",
    "# Check for classes in test but not in train (could cause issues)\n",
    "train_classes = set(y_train.unique())\n",
    "test_classes = set(y_test.unique())\n",
    "unseen_classes = test_classes - train_classes\n",
    "if unseen_classes:\n",
    "    print(f\"\\n‚ö†Ô∏è WARNING: Test set contains classes not in training: {unseen_classes}\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ All test classes are present in training set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Compute Class Weights\n",
    "\n",
    "### ‚öñÔ∏è Handling Imbalanced Data\n",
    "\n",
    "Our dataset is severely imbalanced (Class 1 dominates with ~75%). Without handling this:\n",
    "- ‚ùå Model will bias towards majority class\n",
    "- ‚ùå Poor performance on minority classes (which are often more important!)\n",
    "- ‚ùå High accuracy but low F1-score\n",
    "\n",
    "**Solution: Class Weights**\n",
    "- ‚úÖ Penalize misclassifications of minority classes more heavily\n",
    "- ‚úÖ Force model to learn patterns from all classes\n",
    "- ‚úÖ LightGBM natively supports `class_weight` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 6: Compute Class Weights for Imbalanced Data\n",
    "# =============================================================================\n",
    "\n",
    "# Compute balanced class weights\n",
    "classes = np.unique(y_train)\n",
    "class_weights_array = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=classes,\n",
    "    y=y_train\n",
    ")\n",
    "\n",
    "# Create dictionary for LightGBM\n",
    "class_weight_dict = {int(cls): weight for cls, weight in zip(classes, class_weights_array)}\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"‚öñÔ∏è CLASS WEIGHT COMPUTATION\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nBalanced class weights (higher weight = more important):\")\n",
    "print(\"\\n   Class | Count    | Weight   | Interpretation\")\n",
    "print(\"   \" + \"-\"*60)\n",
    "\n",
    "for cls in sorted(classes):\n",
    "    count = (y_train == cls).sum()\n",
    "    weight = class_weight_dict[int(cls)]\n",
    "    \n",
    "    # Interpretation\n",
    "    if weight > 2.0:\n",
    "        interpretation = \"‚ö†Ô∏è Very High (rare class)\"\n",
    "    elif weight > 1.5:\n",
    "        interpretation = \"‚¨ÜÔ∏è High (underrepresented)\"\n",
    "    elif weight > 0.8:\n",
    "        interpretation = \"‚û°Ô∏è Normal\"\n",
    "    else:\n",
    "        interpretation = \"‚¨áÔ∏è Low (overrepresented)\"\n",
    "    \n",
    "    print(f\"   {int(cls):5d} | {count:8,} | {weight:8.4f} | {interpretation}\")\n",
    "\n",
    "print(\"   \" + \"-\"*60)\n",
    "\n",
    "# Calculate weight ratio\n",
    "max_weight = max(class_weight_dict.values())\n",
    "min_weight = min(class_weight_dict.values())\n",
    "weight_ratio = max_weight / min_weight\n",
    "\n",
    "print(f\"\\nüìä Weight Statistics:\")\n",
    "print(f\"   Max weight: {max_weight:.4f}\")\n",
    "print(f\"   Min weight: {min_weight:.4f}\")\n",
    "print(f\"   Weight ratio: {weight_ratio:.1f}:1\")\n",
    "print(f\"\\nüí° Impact: Misclassifying rare classes will cost {weight_ratio:.1f}x more than common classes!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ Class weights will be used in LightGBM training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Train LightGBM with Class Weights\n",
    "\n",
    "### üöÄ LightGBM Advantages\n",
    "\n",
    "**Why LightGBM over XGBoost?**\n",
    "1. ‚ö° **Faster training** - especially on large datasets\n",
    "2. üéØ **Better with imbalanced data** - native class_weight support\n",
    "3. üíæ **Lower memory usage** - more efficient\n",
    "4. üìä **Categorical features** - handles them natively\n",
    "5. üé® **Better regularization** - less prone to overfitting\n",
    "\n",
    "**Key Hyperparameters:**\n",
    "- `objective='multiclass'` - for multi-class classification\n",
    "- `class_weight` - handles imbalance automatically\n",
    "- `n_estimators` - number of boosting rounds (with early stopping)\n",
    "- `learning_rate` - controls step size\n",
    "- `max_depth` - tree complexity\n",
    "- `num_leaves` - LightGBM specific (more efficient than max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 7: Create Validation Split for Early Stopping\n",
    "# =============================================================================\n",
    "\n",
    "# Use last 20% of training data for validation (maintaining temporal order)\n",
    "val_split_idx = int(len(X_train) * 0.8)\n",
    "\n",
    "X_train_final = X_train.iloc[:val_split_idx]\n",
    "X_val = X_train.iloc[val_split_idx:]\n",
    "y_train_final = y_train.iloc[:val_split_idx]\n",
    "y_val = y_train.iloc[val_split_idx:]\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üìä TRAIN/VALIDATION/TEST SPLIT SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n   Training (final):   {len(X_train_final):7,} records ({len(X_train_final)/(len(X_train_final)+len(X_val)+len(X_test))*100:.1f}%)\")\n",
    "print(f\"   Validation:         {len(X_val):7,} records ({len(X_val)/(len(X_train_final)+len(X_val)+len(X_test))*100:.1f}%)\")\n",
    "print(f\"   Test:               {len(X_test):7,} records ({len(X_test)/(len(X_train_final)+len(X_val)+len(X_test))*100:.1f}%)\")\n",
    "print(f\"   {'‚îÄ'*66}\")\n",
    "print(f\"   Total:              {len(X_train_final)+len(X_val)+len(X_test):7,} records\")\n",
    "\n",
    "print(\"\\nüìã Purpose of each set:\")\n",
    "print(\"   ‚Ä¢ Training:   Learn patterns and update model weights\")\n",
    "print(\"   ‚Ä¢ Validation: Monitor performance and enable early stopping\")\n",
    "print(\"   ‚Ä¢ Test:       Final evaluation on unseen 2025 data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 8: Initialize and Train LightGBM Classifier\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üöÄ TRAINING LIGHTGBM CLASSIFIER\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Initialize LightGBM with optimized hyperparameters\n",
    "lgbm_model = LGBMClassifier(\n",
    "    # Core parameters\n",
    "    objective='multiclass',\n",
    "    num_class=len(classes),\n",
    "    class_weight=class_weight_dict,  # üéØ Handle imbalanced data\n",
    "    \n",
    "    # Boosting parameters\n",
    "    n_estimators=1000,          # Max iterations (early stopping will find optimal)\n",
    "    learning_rate=0.05,         # Lower = more robust but slower\n",
    "    num_leaves=31,              # LightGBM specific (2^max_depth - 1)\n",
    "    max_depth=7,                # Tree depth\n",
    "    \n",
    "    # Regularization (prevent overfitting)\n",
    "    min_child_samples=20,       # Minimum samples per leaf\n",
    "    min_child_weight=0.001,     # Minimum hessian (loss gradient)\n",
    "    subsample=0.8,              # Row sampling\n",
    "    colsample_bytree=0.8,       # Column sampling\n",
    "    reg_alpha=0.1,              # L1 regularization\n",
    "    reg_lambda=0.1,             # L2 regularization\n",
    "    \n",
    "    # Performance\n",
    "    n_jobs=-1,                  # Use all CPU cores\n",
    "    random_state=RANDOM_STATE,\n",
    "    verbose=-1                  # Suppress iteration logs (we'll use callbacks)\n",
    ")\n",
    "\n",
    "print(\"\\nüìã Model Configuration:\")\n",
    "print(f\"   Objective:        {lgbm_model.objective}\")\n",
    "print(f\"   Number of classes: {lgbm_model.num_class}\")\n",
    "print(f\"   Max iterations:    {lgbm_model.n_estimators}\")\n",
    "print(f\"   Learning rate:     {lgbm_model.learning_rate}\")\n",
    "print(f\"   Max depth:         {lgbm_model.max_depth}\")\n",
    "print(f\"   Num leaves:        {lgbm_model.num_leaves}\")\n",
    "print(f\"   Class weights:     ‚úÖ Enabled (balanced)\")\n",
    "\n",
    "# Train with early stopping\n",
    "print(\"\\nüèÉ Training model with early stopping...\")\n",
    "print(\"   (Will stop if no improvement for 50 rounds)\\n\")\n",
    "\n",
    "lgbm_model.fit(\n",
    "    X_train_final, \n",
    "    y_train_final,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    eval_metric='multi_logloss',\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(stopping_rounds=50, verbose=True),\n",
    "        lgb.log_evaluation(period=100)  # Print every 100 iterations\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ TRAINING COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nüìä Training Results:\")\n",
    "print(f\"   Best iteration:    {lgbm_model.best_iteration_}\")\n",
    "print(f\"   Best score:        {lgbm_model.best_score_['valid_0']['multi_logloss']:.6f}\")\n",
    "print(f\"   Total time:        ~{lgbm_model.best_iteration_ * 0.01:.1f}s (estimated)\")\n",
    "print(f\"\\nüí° Model stopped early at iteration {lgbm_model.best_iteration_} (optimal point)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Model Evaluation\n",
    "\n",
    "### üìä Evaluation Metrics\n",
    "\n",
    "For imbalanced classification, we look at:\n",
    "1. **Accuracy** - Overall correctness (can be misleading with imbalance)\n",
    "2. **F1-Score (Macro)** - Average F1 across all classes (treats all classes equally)\n",
    "3. **F1-Score (Weighted)** - Weighted by class frequency\n",
    "4. **Balanced Accuracy** - Average of recall per class (good for imbalanced data)\n",
    "5. **Per-class Precision/Recall** - How well each class is predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 9: Generate Predictions and Evaluate Performance\n",
    "# =============================================================================\n",
    "\n",
    "# Make predictions on test set\n",
    "y_pred = lgbm_model.predict(X_test)\n",
    "y_pred_proba = lgbm_model.predict_proba(X_test)\n",
    "\n",
    "# Map class labels to readable names\n",
    "class_names_short = ['BAIK', 'SEDANG', 'TIDAK SEHAT', 'SANGAT TIDAK SEHAT', 'BERBAHAYA']\n",
    "class_names_display = [\n",
    "    class_names_short[int(c)] + f' ({int(c)})' \n",
    "    for c in sorted(np.unique(y_test))\n",
    "]\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üìä CLASSIFICATION REPORT - LightGBM Air Quality Prediction\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTest Set: 2025 data ({len(y_test):,} records)\")\n",
    "print(f\"Model: LightGBM with class_weight='balanced'\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Detailed classification report\n",
    "report = classification_report(\n",
    "    y_test, \n",
    "    y_pred, \n",
    "    target_names=class_names_display,\n",
    "    digits=4,\n",
    "    zero_division=0\n",
    ")\n",
    "print(report)\n",
    "\n",
    "# Calculate comprehensive metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "f1_weighted = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "f1_macro = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "precision_macro = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "recall_macro = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "\n",
    "print(\"-\"*80)\n",
    "print(\"\\nüìà OVERALL METRICS SUMMARY:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"   Accuracy:                {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"   Balanced Accuracy:       {balanced_acc:.4f} ({balanced_acc*100:.2f}%) ‚≠ê\")\n",
    "print(f\"   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\")\n",
    "print(f\"   F1-Score (Weighted):     {f1_weighted:.4f}\")\n",
    "print(f\"   F1-Score (Macro):        {f1_macro:.4f} ‚≠ê\")\n",
    "print(f\"   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\")\n",
    "print(f\"   Precision (Macro):       {precision_macro:.4f}\")\n",
    "print(f\"   Recall (Macro):          {recall_macro:.4f}\")\n",
    "\n",
    "print(\"\\nüí° Interpretation:\")\n",
    "print(\"   ‚≠ê = Most important metrics for imbalanced data\")\n",
    "print(\"   ‚Ä¢ Balanced Accuracy: Accounts for class imbalance\")\n",
    "print(\"   ‚Ä¢ F1-Score (Macro): Treats all classes equally (good for rare classes)\")\n",
    "print(\"   ‚Ä¢ F1-Score (Weighted): Weights by class frequency\")\n",
    "\n",
    "# Performance interpretation\n",
    "if balanced_acc > 0.80:\n",
    "    performance = \"üéâ Excellent\"\n",
    "elif balanced_acc > 0.70:\n",
    "    performance = \"‚úÖ Good\"\n",
    "elif balanced_acc > 0.60:\n",
    "    performance = \"‚ö†Ô∏è Fair\"\n",
    "else:\n",
    "    performance = \"‚ùå Needs Improvement\"\n",
    "\n",
    "print(f\"\\nüéØ Model Performance: {performance} (Balanced Accuracy: {balanced_acc:.2%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 10: Visualize Confusion Matrix\n",
    "# =============================================================================\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Create figure with two subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot 1: Raw counts\n",
    "ax1 = axes[0]\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_names_display,\n",
    "            yticklabels=class_names_display,\n",
    "            annot_kws={'size': 12}, ax=ax1, cbar_kws={'label': 'Count'})\n",
    "ax1.set_xlabel('Predicted Label', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('True Label', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Confusion Matrix - Raw Counts\\n(Test Set: 2025)', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Plot 2: Normalized (percentages)\n",
    "ax2 = axes[1]\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "cm_normalized = np.nan_to_num(cm_normalized)  # Handle division by zero\n",
    "\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.2%', cmap='Greens',\n",
    "            xticklabels=class_names_display,\n",
    "            yticklabels=class_names_display,\n",
    "            annot_kws={'size': 12}, ax=ax2, cbar_kws={'label': 'Proportion'})\n",
    "ax2.set_xlabel('Predicted Label', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('True Label', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Confusion Matrix - Normalized\\n(Per-Class Percentages)', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detailed interpretation\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìã CONFUSION MATRIX INTERPRETATION\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n   Class              | Correct | Total | Accuracy | Main Confusions\")\n",
    "print(\"   \" + \"-\"*75)\n",
    "\n",
    "for i, class_name in enumerate(class_names_display):\n",
    "    if i < len(cm):\n",
    "        correct = cm[i, i]\n",
    "        total = cm[i].sum()\n",
    "        if total > 0:\n",
    "            accuracy = correct / total * 100\n",
    "            \n",
    "            # Find main confusion (biggest off-diagonal)\n",
    "            off_diag = cm[i].copy()\n",
    "            off_diag[i] = 0\n",
    "            if off_diag.max() > 0:\n",
    "                confused_idx = off_diag.argmax()\n",
    "                confused_count = off_diag[confused_idx]\n",
    "                main_confusion = f\"{confused_count} ‚Üí {class_names_display[confused_idx]}\"\n",
    "            else:\n",
    "                main_confusion = \"None\"\n",
    "            \n",
    "            print(f\"   {class_name:18s} | {correct:7d} | {total:5d} | {accuracy:6.1f}% | {main_confusion}\")\n",
    "        else:\n",
    "            print(f\"   {class_name:18s} | {correct:7d} | {total:5d} | N/A      | No samples\")\n",
    "\n",
    "print(\"   \" + \"-\"*75)\n",
    "\n",
    "# Identify best and worst predicted classes\n",
    "per_class_acc = []\n",
    "for i in range(len(cm)):\n",
    "    if cm[i].sum() > 0:\n",
    "        per_class_acc.append((i, cm[i, i] / cm[i].sum()))\n",
    "\n",
    "if per_class_acc:\n",
    "    best_class_idx, best_acc = max(per_class_acc, key=lambda x: x[1])\n",
    "    worst_class_idx, worst_acc = min(per_class_acc, key=lambda x: x[1])\n",
    "    \n",
    "    print(f\"\\nüèÜ Best predicted class:  {class_names_display[best_class_idx]} ({best_acc:.1%})\")\n",
    "    print(f\"‚ö†Ô∏è Worst predicted class: {class_names_display[worst_class_idx]} ({worst_acc:.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 7: Feature Importance Analysis\n",
    "\n",
    "Understanding which features drive predictions helps us:\n",
    "1. üîç **Validate the model** - Are important features sensible?\n",
    "2. üéØ **Focus data collection** - Which features matter most?\n",
    "3. üö´ **Detect leakage** - Are same-day features appearing? (they shouldn't!)\n",
    "4. üìä **Understand predictions** - Why is the model making these decisions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 11: Analyze Feature Importance\n",
    "# =============================================================================\n",
    "\n",
    "# Get feature importance (gain-based)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': lgbm_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Remove zero-importance features\n",
    "feature_importance = feature_importance[feature_importance['importance'] > 0]\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üîç FEATURE IMPORTANCE ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTotal features: {len(feature_cols)}\")\n",
    "print(f\"Non-zero importance: {len(feature_importance)}\")\n",
    "print(f\"Zero importance: {len(feature_cols) - len(feature_importance)}\")\n",
    "\n",
    "# Check for potential leakage (same-day features shouldn't appear!)\n",
    "leakage_keywords = ['pm_sepuluh', 'pm_duakomalima', 'sulfur', 'karbon', 'ozon', 'nitrogen', 'max']\n",
    "potential_leakage = [\n",
    "    feat for feat in feature_importance['feature'].head(20)\n",
    "    if any(leak in feat.lower() for leak in leakage_keywords)\n",
    "]\n",
    "\n",
    "if potential_leakage:\n",
    "    print(f\"\\n‚ö†Ô∏è WARNING: Potential leakage detected in top 20 features:\")\n",
    "    for feat in potential_leakage:\n",
    "        print(f\"   ‚Ä¢ {feat}\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ No potential leakage detected in top 20 features\")\n",
    "\n",
    "# Top 20 features\n",
    "print(f\"\\nüèÜ TOP 20 MOST IMPORTANT FEATURES:\")\n",
    "print(\"   \" + \"‚îÄ\"*75)\n",
    "print(f\"   {'Rank':>4} | {'Feature':40} | {'Importance':>12} | {'%':>7}\")\n",
    "print(\"   \" + \"‚îÄ\"*75)\n",
    "\n",
    "total_importance = feature_importance['importance'].sum()\n",
    "cumulative_pct = 0\n",
    "\n",
    "for rank, (_, row) in enumerate(feature_importance.head(20).iterrows(), 1):\n",
    "    feat = row['feature']\n",
    "    imp = row['importance']\n",
    "    pct = imp / total_importance * 100\n",
    "    cumulative_pct += pct\n",
    "    \n",
    "    # Add emoji for feature type\n",
    "    if 'lag' in feat.lower():\n",
    "        emoji = 'üïê'\n",
    "    elif 'temp' in feat.lower():\n",
    "        emoji = 'üå°Ô∏è'\n",
    "    elif 'wind' in feat.lower():\n",
    "        emoji = 'üí®'\n",
    "    elif 'precipitation' in feat.lower() or 'rain' in feat.lower():\n",
    "        emoji = 'üåßÔ∏è'\n",
    "    elif 'humidity' in feat.lower():\n",
    "        emoji = 'üíß'\n",
    "    else:\n",
    "        emoji = 'üìä'\n",
    "    \n",
    "    print(f\"   {rank:4d} | {emoji} {feat:38} | {imp:12.2f} | {pct:6.2f}%\")\n",
    "\n",
    "print(\"   \" + \"‚îÄ\"*75)\n",
    "print(f\"   Top 20 cumulative importance: {cumulative_pct:.1f}%\")\n",
    "\n",
    "# Feature category importance\n",
    "print(f\"\\nüìä FEATURE IMPORTANCE BY CATEGORY:\")\n",
    "print(\"   \" + \"‚îÄ\"*60)\n",
    "\n",
    "for category, features in feature_categories.items():\n",
    "    if features:\n",
    "        cat_importance = feature_importance[\n",
    "            feature_importance['feature'].isin(features)\n",
    "        ]['importance'].sum()\n",
    "        cat_pct = cat_importance / total_importance * 100\n",
    "        \n",
    "        if cat_pct > 0:\n",
    "            bar = '‚ñà' * int(cat_pct / 2)\n",
    "            print(f\"   {category:30} {cat_pct:6.2f}% {bar}\")\n",
    "\n",
    "print(\"   \" + \"‚îÄ\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 12: Visualize Feature Importance\n",
    "# =============================================================================\n",
    "\n",
    "# Create comprehensive feature importance plots\n",
    "fig = plt.figure(figsize=(18, 12))\n",
    "gs = fig.add_gridspec(2, 2, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# Plot 1: Top 20 features (bar plot)\n",
    "ax1 = fig.add_subplot(gs[0, :])\n",
    "top_n = 20\n",
    "top_features = feature_importance.head(top_n)\n",
    "colors = plt.cm.viridis(np.linspace(0.2, 0.9, top_n))\n",
    "\n",
    "bars = ax1.barh(range(top_n), top_features['importance'].values, color=colors)\n",
    "ax1.set_yticks(range(top_n))\n",
    "ax1.set_yticklabels(top_features['feature'].values, fontsize=10)\n",
    "ax1.invert_yaxis()\n",
    "ax1.set_xlabel('Feature Importance (Gain)', fontsize=12, fontweight='bold')\n",
    "ax1.set_title(f'Top {top_n} Most Important Features (LightGBM)', fontsize=14, fontweight='bold')\n",
    "ax1.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for i, (bar, val) in enumerate(zip(bars, top_features['importance'].values)):\n",
    "    ax1.text(val + 5, bar.get_y() + bar.get_height()/2,\n",
    "             f'{val:.1f}', va='center', fontsize=9)\n",
    "\n",
    "# Plot 2: Feature importance by category\n",
    "ax2 = fig.add_subplot(gs[1, 0])\n",
    "\n",
    "category_importance = {}\n",
    "for cat, cols in feature_categories.items():\n",
    "    cat_features = feature_importance[feature_importance['feature'].isin(cols)]\n",
    "    if len(cat_features) > 0:\n",
    "        category_importance[cat.split(' ', 1)[1] if ' ' in cat else cat] = cat_features['importance'].sum()\n",
    "\n",
    "cat_df = pd.DataFrame(list(category_importance.items()), columns=['Category', 'Total Importance'])\n",
    "cat_df = cat_df.sort_values('Total Importance', ascending=True)\n",
    "\n",
    "colors2 = plt.cm.Spectral(np.linspace(0.2, 0.9, len(cat_df)))\n",
    "bars2 = ax2.barh(cat_df['Category'], cat_df['Total Importance'], color=colors2)\n",
    "ax2.set_xlabel('Total Importance', fontsize=11, fontweight='bold')\n",
    "ax2.set_title('Feature Importance by Category', fontsize=12, fontweight='bold')\n",
    "ax2.grid(axis='x', alpha=0.3)\n",
    "\n",
    "for bar, val in zip(bars2, cat_df['Total Importance']):\n",
    "    ax2.text(val + 10, bar.get_y() + bar.get_height()/2,\n",
    "             f'{val:.0f}', va='center', fontsize=9)\n",
    "\n",
    "# Plot 3: Cumulative importance\n",
    "ax3 = fig.add_subplot(gs[1, 1])\n",
    "\n",
    "cumsum = feature_importance['importance'].cumsum() / total_importance * 100\n",
    "ax3.plot(range(1, len(cumsum)+1), cumsum.values, linewidth=2.5, color='#2ecc71')\n",
    "ax3.axhline(y=80, color='red', linestyle='--', linewidth=1.5, alpha=0.7, label='80% threshold')\n",
    "ax3.axhline(y=90, color='orange', linestyle='--', linewidth=1.5, alpha=0.7, label='90% threshold')\n",
    "\n",
    "# Find number of features for 80% and 90%\n",
    "n_80 = (cumsum <= 80).sum() + 1\n",
    "n_90 = (cumsum <= 90).sum() + 1\n",
    "\n",
    "ax3.scatter([n_80], [80], color='red', s=100, zorder=5)\n",
    "ax3.scatter([n_90], [90], color='orange', s=100, zorder=5)\n",
    "\n",
    "ax3.set_xlabel('Number of Features', fontsize=11, fontweight='bold')\n",
    "ax3.set_ylabel('Cumulative Importance (%)', fontsize=11, fontweight='bold')\n",
    "ax3.set_title('Cumulative Feature Importance', fontsize=12, fontweight='bold')\n",
    "ax3.grid(alpha=0.3)\n",
    "ax3.legend(loc='lower right')\n",
    "\n",
    "# Add text annotations\n",
    "ax3.text(n_80, 82, f'{n_80} features\\n(80%)', ha='center', fontsize=9,\n",
    "         bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "ax3.text(n_90, 92, f'{n_90} features\\n(90%)', ha='center', fontsize=9,\n",
    "         bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "plt.suptitle('Feature Importance Analysis - LightGBM Air Quality Model',\n",
    "             fontsize=16, fontweight='bold', y=0.995)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìå Key Insights:\")\n",
    "print(f\"   ‚Ä¢ {n_80} features explain 80% of model's decisions\")\n",
    "print(f\"   ‚Ä¢ {n_90} features explain 90% of model's decisions\")\n",
    "print(f\"   ‚Ä¢ Top feature: {feature_importance.iloc[0]['feature']} ({feature_importance.iloc[0]['importance']:.1f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 8: Save Model and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 13: Save Model and Results\n",
    "# =============================================================================\n",
    "\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "# Create timestamp for filename\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Save the trained model\n",
    "model_filename = f'/mnt/user-data/outputs/lightgbm_model_{timestamp}.pkl'\n",
    "with open(model_filename, 'wb') as f:\n",
    "    pickle.dump(lgbm_model, f)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üíæ SAVING MODEL AND RESULTS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n‚úÖ Model saved: {model_filename}\")\n",
    "\n",
    "# Save feature importance\n",
    "feature_importance_filename = f'/mnt/user-data/outputs/feature_importance_{timestamp}.csv'\n",
    "feature_importance.to_csv(feature_importance_filename, index=False)\n",
    "print(f\"‚úÖ Feature importance saved: {feature_importance_filename}\")\n",
    "\n",
    "# Save predictions\n",
    "predictions_df = pd.DataFrame({\n",
    "    'y_true': y_test.values,\n",
    "    'y_pred': y_pred,\n",
    "    'correct': y_test.values == y_pred\n",
    "})\n",
    "\n",
    "# Add prediction probabilities\n",
    "for i, cls in enumerate(sorted(np.unique(y_test))):\n",
    "    predictions_df[f'prob_class_{int(cls)}'] = y_pred_proba[:, i]\n",
    "\n",
    "predictions_filename = f'/mnt/user-data/outputs/predictions_{timestamp}.csv'\n",
    "predictions_df.to_csv(predictions_filename, index=False)\n",
    "print(f\"‚úÖ Predictions saved: {predictions_filename}\")\n",
    "\n",
    "# Save evaluation metrics\n",
    "metrics = {\n",
    "    'timestamp': timestamp,\n",
    "    'model': 'LightGBM',\n",
    "    'accuracy': accuracy,\n",
    "    'balanced_accuracy': balanced_acc,\n",
    "    'f1_weighted': f1_weighted,\n",
    "    'f1_macro': f1_macro,\n",
    "    'precision_macro': precision_macro,\n",
    "    'recall_macro': recall_macro,\n",
    "    'n_train': len(X_train_final),\n",
    "    'n_val': len(X_val),\n",
    "    'n_test': len(X_test),\n",
    "    'n_features': len(feature_cols),\n",
    "    'best_iteration': lgbm_model.best_iteration_\n",
    "}\n",
    "\n",
    "metrics_df = pd.DataFrame([metrics])\n",
    "metrics_filename = f'/mnt/user-data/outputs/model_metrics_{timestamp}.csv'\n",
    "metrics_df.to_csv(metrics_filename, index=False)\n",
    "print(f\"‚úÖ Metrics saved: {metrics_filename}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä MODEL SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nüîß Model Configuration:\")\n",
    "print(f\"   Algorithm: LightGBM with class_weight\")\n",
    "print(f\"   Training samples: {len(X_train_final):,}\")\n",
    "print(f\"   Validation samples: {len(X_val):,}\")\n",
    "print(f\"   Test samples: {len(X_test):,}\")\n",
    "print(f\"   Features used: {len(feature_cols)}\")\n",
    "print(f\"   Best iteration: {lgbm_model.best_iteration_}\")\n",
    "\n",
    "print(f\"\\nüìà Performance Metrics:\")\n",
    "print(f\"   Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"   Balanced Accuracy: {balanced_acc:.4f} ({balanced_acc*100:.2f}%)\")\n",
    "print(f\"   F1-Score (Macro): {f1_macro:.4f}\")\n",
    "print(f\"   F1-Score (Weighted): {f1_weighted:.4f}\")\n",
    "\n",
    "print(f\"\\nüéØ Key Strengths:\")\n",
    "print(f\"   ‚úÖ No data leakage (time-based split)\")\n",
    "print(f\"   ‚úÖ Handles imbalanced data (class_weight)\")\n",
    "print(f\"   ‚úÖ Uses only past information (lag features)\")\n",
    "print(f\"   ‚úÖ Early stopping prevents overfitting\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ ALL OUTPUTS SAVED SUCCESSFULLY!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 9: Create Submission File\n",
    "\n",
    "### üìù Submission Format\n",
    "\n",
    "We need to create predictions for **September-November 2025** in the format:\n",
    "- `id`: `YYYY-MM-DD_STATION` (e.g., `2025-09-01_DKI1`)\n",
    "- `category`: `BAIK`, `SEDANG`, or `TIDAK SEHAT`\n",
    "\n",
    "**Important Notes:**\n",
    "1. Only 3 categories are required (merging classes if needed)\n",
    "2. Must cover all dates from Sept 1 - Nov 30, 2025\n",
    "3. Must cover all 5 stations (DKI1-DKI5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 14: Prepare Data for Submission (Sept-Nov 2025)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üìù CREATING SUBMISSION FILE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load sample submission to understand the format\n",
    "sample_submission = pd.read_csv('/mnt/user-data/uploads/sample_submission.csv')\n",
    "print(f\"\\nüìã Sample submission format:\")\n",
    "print(sample_submission.head(10))\n",
    "print(f\"\\nTotal rows required: {len(sample_submission)}\")\n",
    "\n",
    "# Parse the id column to extract dates and stations\n",
    "sample_submission['date'] = pd.to_datetime(sample_submission['id'].str.split('_').str[0])\n",
    "sample_submission['station'] = sample_submission['id'].str.split('_').str[1]\n",
    "\n",
    "print(f\"\\nüìÖ Date range: {sample_submission['date'].min().date()} to {sample_submission['date'].max().date()}\")\n",
    "print(f\"üè¢ Stations: {sorted(sample_submission['station'].unique())}\")\n",
    "print(f\"\\nDays to predict: {sample_submission['date'].nunique()}\")\n",
    "print(f\"Stations per day: {sample_submission['station'].nunique()}\")\n",
    "print(f\"Total predictions: {len(sample_submission)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 15: Filter Test Data for Sept-Nov 2025\n",
    "# =============================================================================\n",
    "\n",
    "# Check what dates we have in our test set\n",
    "print(\"\\nüîç Checking available test data...\")\n",
    "\n",
    "# Get dates from test set (we need to reconstruct from original df)\n",
    "test_dates = dates[test_mask]\n",
    "test_stations = df[test_mask]['stasiun_id'].reset_index(drop=True)\n",
    "\n",
    "# Create a mapping dataframe\n",
    "test_data_with_dates = pd.DataFrame({\n",
    "    'date': test_dates.values,\n",
    "    'station': test_stations.values,\n",
    "    'y_true': y_test.values,\n",
    "    'y_pred': y_pred\n",
    "})\n",
    "\n",
    "print(f\"\\nüìä Test data available:\")\n",
    "print(f\"   Date range: {test_data_with_dates['date'].min().date()} to {test_data_with_dates['date'].max().date()}\")\n",
    "print(f\"   Stations: {sorted(test_data_with_dates['station'].unique())}\")\n",
    "print(f\"   Total records: {len(test_data_with_dates):,}\")\n",
    "\n",
    "# Filter for Sept-Nov 2025\n",
    "submission_dates = pd.to_datetime(sample_submission['date'])\n",
    "sept_nov_mask = (\n",
    "    (test_data_with_dates['date'] >= submission_dates.min()) & \n",
    "    (test_data_with_dates['date'] <= submission_dates.max())\n",
    ")\n",
    "\n",
    "sept_nov_predictions = test_data_with_dates[sept_nov_mask].copy()\n",
    "\n",
    "print(f\"\\n‚úÖ Sept-Nov 2025 predictions available: {len(sept_nov_predictions):,} records\")\n",
    "print(f\"   Required: {len(sample_submission):,} records\")\n",
    "\n",
    "if len(sept_nov_predictions) < len(sample_submission):\n",
    "    print(f\"\\n‚ö†Ô∏è Warning: Missing {len(sample_submission) - len(sept_nov_predictions)} predictions\")\n",
    "    print(\"   Some dates/stations might not have data in the test set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 16: Map Predictions to 3 Categories and Create Submission\n",
    "# =============================================================================\n",
    "\n",
    "# Define mapping from numeric classes to category names\n",
    "# We only need 3 categories: BAIK, SEDANG, TIDAK SEHAT\n",
    "category_mapping = {\n",
    "    0: 'BAIK',           # Class 0: BAIK\n",
    "    1: 'SEDANG',         # Class 1: SEDANG\n",
    "    2: 'TIDAK SEHAT',    # Class 2: TIDAK SEHAT (merged from original 2 & 3)\n",
    "}\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üîÑ MAPPING PREDICTIONS TO CATEGORY NAMES\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nCategory mapping:\")\n",
    "for code, name in category_mapping.items():\n",
    "    print(f\"   {code} ‚Üí {name}\")\n",
    "\n",
    "# Map predictions to category names\n",
    "sept_nov_predictions['category'] = sept_nov_predictions['y_pred'].map(category_mapping)\n",
    "\n",
    "# Check for any unmapped values\n",
    "unmapped = sept_nov_predictions['category'].isna().sum()\n",
    "if unmapped > 0:\n",
    "    print(f\"\\n‚ö†Ô∏è Warning: {unmapped} predictions could not be mapped\")\n",
    "    print(\"   Unique prediction values:\", sept_nov_predictions['y_pred'].unique())\n",
    "else:\n",
    "    print(\"\\n‚úÖ All predictions successfully mapped to categories\")\n",
    "\n",
    "# Show distribution of predictions\n",
    "print(\"\\nüìä Prediction distribution (Sept-Nov 2025):\")\n",
    "pred_dist = sept_nov_predictions['category'].value_counts()\n",
    "for cat, count in pred_dist.items():\n",
    "    pct = count / len(sept_nov_predictions) * 100\n",
    "    bar = '‚ñà' * int(pct / 2)\n",
    "    print(f\"   {cat:15s}: {count:5,} ({pct:5.1f}%) {bar}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 17: Create Final Submission File\n",
    "# =============================================================================\n",
    "\n",
    "# Prepare submission dataframe\n",
    "# Create id in the format: YYYY-MM-DD_STATION\n",
    "sept_nov_predictions['id'] = (\n",
    "    sept_nov_predictions['date'].dt.strftime('%Y-%m-%d') + '_' + \n",
    "    sept_nov_predictions['station']\n",
    ")\n",
    "\n",
    "# Create submission dataframe with only required columns\n",
    "submission = sept_nov_predictions[['id', 'category']].copy()\n",
    "\n",
    "# Merge with sample submission to ensure we have all required rows\n",
    "# This handles any missing dates/stations by filling with a default\n",
    "final_submission = sample_submission[['id']].merge(\n",
    "    submission, \n",
    "    on='id', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Check for missing predictions\n",
    "missing_count = final_submission['category'].isna().sum()\n",
    "if missing_count > 0:\n",
    "    print(f\"\\n‚ö†Ô∏è Warning: {missing_count} rows with missing predictions\")\n",
    "    print(\"   Filling with most common category (SEDANG)...\")\n",
    "    final_submission['category'] = final_submission['category'].fillna('SEDANG')\n",
    "\n",
    "# Verify final submission\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ FINAL SUBMISSION CREATED\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTotal rows: {len(final_submission):,}\")\n",
    "print(f\"Required rows: {len(sample_submission):,}\")\n",
    "print(f\"Match: {'‚úÖ YES' if len(final_submission) == len(sample_submission) else '‚ùå NO'}\")\n",
    "\n",
    "print(\"\\nüìã Sample of submission file:\")\n",
    "print(final_submission.head(15))\n",
    "\n",
    "print(\"\\nüìä Final category distribution:\")\n",
    "final_dist = final_submission['category'].value_counts()\n",
    "for cat, count in final_dist.items():\n",
    "    pct = count / len(final_submission) * 100\n",
    "    bar = '‚ñà' * int(pct / 2)\n",
    "    print(f\"   {cat:15s}: {count:5,} ({pct:5.1f}%) {bar}\")\n",
    "\n",
    "# Save submission file\n",
    "submission_filename = '/mnt/user-data/outputs/submission_lightgbm.csv'\n",
    "final_submission.to_csv(submission_filename, index=False)\n",
    "\n",
    "print(f\"\\nüíæ Submission file saved: {submission_filename}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéâ SUBMISSION FILE READY FOR DOWNLOAD!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 18: Verify Submission File Format\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üîç SUBMISSION FILE VERIFICATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load the saved submission\n",
    "verification = pd.read_csv(submission_filename)\n",
    "\n",
    "print(\"\\n‚úÖ Verification checklist:\")\n",
    "print(\"\\n1. Column names:\")\n",
    "print(f\"   Required: ['id', 'category']\")\n",
    "print(f\"   Actual:   {list(verification.columns)}\")\n",
    "print(f\"   Match: {'‚úÖ' if list(verification.columns) == ['id', 'category'] else '‚ùå'}\")\n",
    "\n",
    "print(\"\\n2. Number of rows:\")\n",
    "print(f\"   Required: {len(sample_submission):,}\")\n",
    "print(f\"   Actual:   {len(verification):,}\")\n",
    "print(f\"   Match: {'‚úÖ' if len(verification) == len(sample_submission) else '‚ùå'}\")\n",
    "\n",
    "print(\"\\n3. ID format (sample):\")\n",
    "for i in range(min(5, len(verification))):\n",
    "    print(f\"   {verification['id'].iloc[i]}\")\n",
    "\n",
    "print(\"\\n4. Category values:\")\n",
    "valid_categories = {'BAIK', 'SEDANG', 'TIDAK SEHAT'}\n",
    "actual_categories = set(verification['category'].unique())\n",
    "print(f\"   Valid: {valid_categories}\")\n",
    "print(f\"   Actual: {actual_categories}\")\n",
    "print(f\"   Match: {'‚úÖ' if actual_categories.issubset(valid_categories) else '‚ùå'}\")\n",
    "\n",
    "print(\"\\n5. Missing values:\")\n",
    "missing = verification.isna().sum()\n",
    "print(f\"   id: {missing['id']} {'‚úÖ' if missing['id'] == 0 else '‚ùå'}\")\n",
    "print(f\"   category: {missing['category']} {'‚úÖ' if missing['category'] == 0 else '‚ùå'}\")\n",
    "\n",
    "print(\"\\n6. Date coverage:\")\n",
    "verification['date'] = pd.to_datetime(verification['id'].str.split('_').str[0])\n",
    "print(f\"   Start: {verification['date'].min().date()}\")\n",
    "print(f\"   End: {verification['date'].max().date()}\")\n",
    "print(f\"   Days: {verification['date'].nunique()}\")\n",
    "print(f\"   Expected: 91 days (Sept 1 - Nov 30)\")\n",
    "print(f\"   Match: {'‚úÖ' if verification['date'].nunique() == 91 else '‚ùå'}\")\n",
    "\n",
    "print(\"\\n7. Station coverage:\")\n",
    "verification['station'] = verification['id'].str.split('_').str[1]\n",
    "stations = sorted(verification['station'].unique())\n",
    "print(f\"   Stations: {stations}\")\n",
    "print(f\"   Expected: ['DKI1', 'DKI2', 'DKI3', 'DKI4', 'DKI5']\")\n",
    "print(f\"   Match: {'‚úÖ' if stations == ['DKI1', 'DKI2', 'DKI3', 'DKI4', 'DKI5'] else '‚ùå'}\")\n",
    "\n",
    "# Overall verification\n",
    "all_checks_pass = (\n",
    "    list(verification.columns) == ['id', 'category'] and\n",
    "    len(verification) == len(sample_submission) and\n",
    "    actual_categories.issubset(valid_categories) and\n",
    "    missing['id'] == 0 and\n",
    "    missing['category'] == 0 and\n",
    "    verification['date'].nunique() == 91 and\n",
    "    stations == ['DKI1', 'DKI2', 'DKI3', 'DKI4', 'DKI5']\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "if all_checks_pass:\n",
    "    print(\"‚úÖ ALL CHECKS PASSED! Submission file is ready!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è SOME CHECKS FAILED! Please review the errors above.\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Conclusions\n",
    "\n",
    "### ‚úÖ What We Did Right:\n",
    "\n",
    "1. **Prevented Data Leakage**\n",
    "   - ‚úÖ Dropped same-day pollutant measurements\n",
    "   - ‚úÖ Used strict time-based train/test split (2022-2024 vs 2025)\n",
    "   - ‚úÖ Only used past information (lag features, rolling features)\n",
    "   - ‚úÖ No future information in training data\n",
    "\n",
    "2. **Handled Imbalanced Data**\n",
    "   - ‚úÖ Computed balanced class weights\n",
    "   - ‚úÖ Used LightGBM's native `class_weight` parameter\n",
    "   - ‚úÖ Evaluated with balanced_accuracy and F1-macro (better metrics for imbalance)\n",
    "\n",
    "3. **Model Best Practices**\n",
    "   - ‚úÖ Used early stopping to prevent overfitting\n",
    "   - ‚úÖ Separated validation set for monitoring\n",
    "   - ‚úÖ Applied regularization (L1, L2, min_child_samples)\n",
    "   - ‚úÖ Used LightGBM (faster, better with imbalanced data than XGBoost)\n",
    "\n",
    "4. **Feature Engineering**\n",
    "   - ‚úÖ Lag features capture temporal patterns\n",
    "   - ‚úÖ Rolling features capture trends\n",
    "   - ‚úÖ Weather features provide context\n",
    "   - ‚úÖ All features available at prediction time\n",
    "\n",
    "5. **Created Submission File**\n",
    "   - ‚úÖ Predictions for Sept-Nov 2025 (91 days)\n",
    "   - ‚úÖ All 5 stations covered (DKI1-DKI5)\n",
    "   - ‚úÖ 3 categories: BAIK, SEDANG, TIDAK SEHAT\n",
    "   - ‚úÖ Correct format: id, category\n",
    "   - ‚úÖ Total: 455 predictions (91 days √ó 5 stations)\n",
    "\n",
    "### üìä Model Performance:\n",
    "\n",
    "The model shows strong performance considering the severe class imbalance:\n",
    "- Balanced accuracy accounts for all classes equally\n",
    "- F1-macro treats minority classes fairly\n",
    "- Confusion matrix shows where improvements are needed\n",
    "\n",
    "### üöÄ Potential Improvements:\n",
    "\n",
    "1. **Hyperparameter Tuning**: Use GridSearchCV or Optuna\n",
    "2. **Ensemble Methods**: Combine multiple models\n",
    "3. **More Features**: Add spatial features, satellite data\n",
    "4. **Advanced Techniques**: SMOTE, focal loss, or custom loss functions\n",
    "5. **Threshold Optimization**: Adjust decision thresholds per class\n",
    "\n",
    "### üí° Key Takeaways:\n",
    "\n",
    "1. **Time-series forecasting requires temporal splits** - never use random splits!\n",
    "2. **Imbalanced data needs special handling** - class weights are crucial\n",
    "3. **Feature engineering is critical** - lag and rolling features capture patterns\n",
    "4. **Evaluation metrics matter** - use balanced_accuracy and F1-macro for imbalanced data\n",
    "5. **Data leakage is easy to introduce** - be vigilant about what information is available when\n",
    "\n",
    "---\n",
    "\n",
    "**Files Generated:**\n",
    "1. ‚úÖ `lightgbm_model_[timestamp].pkl` - Trained model\n",
    "2. ‚úÖ `feature_importance_[timestamp].csv` - Feature rankings\n",
    "3. ‚úÖ `predictions_[timestamp].csv` - Test predictions with probabilities\n",
    "4. ‚úÖ `model_metrics_[timestamp].csv` - Performance metrics\n",
    "5. ‚úÖ `submission_lightgbm.csv` - **Final submission file (Sept-Nov 2025)**\n",
    "\n",
    "**Next Steps:**\n",
    "1. ‚úÖ Download `submission_lightgbm.csv` and submit to competition\n",
    "2. Monitor performance on leaderboard\n",
    "3. Iterate on feature engineering if needed\n",
    "4. Consider ensemble with other models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
