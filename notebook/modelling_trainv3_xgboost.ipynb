{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3632be6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Libraries & Config Loaded, Master.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration\n",
    "DATA_PATH = r\"../processed_data/\"\n",
    "SAMPLE_SUB_PATH = r\"../sample_submission.csv\"\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "print(\"âœ“ Libraries & Config Loaded, Master.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5606954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Data loaded. Total rows: 5175\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_PATH + \"master_df_unscaled.csv\", parse_dates=['tanggal'])\n",
    "\n",
    "# Mapping kategori untuk referensi evaluasi nanti\n",
    "CATEGORY_MAP = {'BAIK': 0, 'SEDANG': 1, 'TIDAK SEHAT': 2}\n",
    "REVERSE_MAP = {v: k for k, v in CATEGORY_MAP.items()}\n",
    "\n",
    "# Encode Stasiun\n",
    "le_stasiun = LabelEncoder()\n",
    "df['stasiun_encoded'] = le_stasiun.fit_transform(df['stasiun'])\n",
    "\n",
    "# Pastikan tidak ada target angka yang NaN untuk training\n",
    "df = df.dropna(subset=['pm_sepuluh', 'pm_duakomalima'])\n",
    "\n",
    "print(f\"âœ“ Data loaded. Total rows: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cad4a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "LAG_FEATURES = ['pm_sepuluh_lag_1d', 'pm_sepuluh_lag_7d', 'pm_duakomalima_lag_1d', 'pm_duakomalima_lag_7d']\n",
    "WEATHER_FEATURES = ['temp_max', 'temp_min', 'temp_mean', 'precipitation_sum', 'precipitation_hours',\n",
    "                    'wind_speed_max', 'wind_speed_mean', 'humidity_mean', 'humidity_max', 'humidity_min',\n",
    "                    'cloud_cover_mean', 'pressure_mean', 'radiation_sum', 'wind_gusts_max', \n",
    "                    'wind_sin', 'wind_cos']\n",
    "TIME_FEATURES = ['year', 'month', 'is_weekend', 'is_holiday_nasional']\n",
    "ROLLING_FEATURES = ['precipitation_sum_rolling_3d_mean', 'temp_mean_rolling_3d_mean']\n",
    "CAT_FEATURES = ['stasiun_encoded']\n",
    "\n",
    "# Convert lag columns to numeric FIRST (in case they're strings)\n",
    "for col in LAG_FEATURES:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Tambahkan fitur Delta/Momentum\n",
    "df['pm25_delta'] = df['pm_duakomalima_lag_1d'] - df['pm_duakomalima_lag_7d']\n",
    "df['pm10_delta'] = df['pm_sepuluh_lag_1d'] - df['pm_sepuluh_lag_7d']\n",
    "\n",
    "FEATURES = LAG_FEATURES + WEATHER_FEATURES + TIME_FEATURES + ROLLING_FEATURES + CAT_FEATURES + ['pm25_delta', 'pm10_delta']\n",
    "\n",
    "# Split Data\n",
    "train_mask = df['tanggal'].dt.year < 2025\n",
    "test_mask = df['tanggal'].dt.year >= 2025\n",
    "\n",
    "# Split ulang data dengan fitur baru\n",
    "X_train, X_test = df[train_mask][FEATURES].fillna(-1), df[test_mask][FEATURES].fillna(-1)\n",
    "y_train_pm10, y_test_pm10 = df[train_mask]['pm_sepuluh'], df[test_mask]['pm_sepuluh']\n",
    "y_train_pm25, y_test_pm25 = df[train_mask]['pm_duakomalima'], df[test_mask]['pm_duakomalima']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8eb7db79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Training PM10 Regressor with Heavy Weights...\n",
      "0:\tlearn: 17.1260795\ttest: 17.5588349\tbest: 17.5588349 (0)\ttotal: 175ms\tremaining: 5m 49s\n",
      "200:\tlearn: 7.8667353\ttest: 9.9587245\tbest: 9.9587245 (200)\ttotal: 7.88s\tremaining: 1m 10s\n",
      "400:\tlearn: 6.9496226\ttest: 9.8857630\tbest: 9.8760455 (324)\ttotal: 15.9s\tremaining: 1m 3s\n",
      "600:\tlearn: 6.4402825\ttest: 9.8761540\tbest: 9.8670561 (568)\ttotal: 23.4s\tremaining: 54.6s\n",
      "800:\tlearn: 6.1563073\ttest: 9.8608881\tbest: 9.8608881 (800)\ttotal: 31.3s\tremaining: 46.8s\n",
      "1000:\tlearn: 5.9724676\ttest: 9.8457959\tbest: 9.8451815 (983)\ttotal: 38.9s\tremaining: 38.8s\n",
      "1200:\tlearn: 5.7949230\ttest: 9.8392419\tbest: 9.8381379 (1047)\ttotal: 46.4s\tremaining: 30.9s\n",
      "1400:\tlearn: 5.6712976\ttest: 9.8365591\tbest: 9.8352656 (1378)\ttotal: 53.8s\tremaining: 23s\n",
      "1600:\tlearn: 5.5780425\ttest: 9.8316675\tbest: 9.8308355 (1596)\ttotal: 1m 1s\tremaining: 15.2s\n",
      "1800:\tlearn: 5.4921486\ttest: 9.8222341\tbest: 9.8206882 (1755)\ttotal: 1m 8s\tremaining: 7.54s\n",
      "1999:\tlearn: 5.4075390\ttest: 9.8172399\tbest: 9.8165122 (1995)\ttotal: 1m 15s\tremaining: 0us\n",
      "\n",
      "bestTest = 9.816512152\n",
      "bestIteration = 1995\n",
      "\n",
      "Shrink model to first 1996 iterations.\n",
      "\n",
      "ðŸš€ Training PM2.5 Regressor with Heavy Weights...\n",
      "0:\tlearn: 14.9062903\ttest: 25.4806605\tbest: 25.4806605 (0)\ttotal: 31.6ms\tremaining: 1m 3s\n",
      "200:\tlearn: 10.9191902\ttest: 12.8623827\tbest: 12.8621130 (196)\ttotal: 7.34s\tremaining: 1m 5s\n",
      "400:\tlearn: 9.4919395\ttest: 12.6823032\tbest: 12.6747175 (388)\ttotal: 14.7s\tremaining: 58.8s\n",
      "600:\tlearn: 8.5277920\ttest: 12.6672868\tbest: 12.6541179 (453)\ttotal: 22.3s\tremaining: 52s\n",
      "800:\tlearn: 7.7245781\ttest: 12.6389890\tbest: 12.6221952 (740)\ttotal: 30.3s\tremaining: 45.4s\n",
      "1000:\tlearn: 7.2236671\ttest: 12.6518473\tbest: 12.6221952 (740)\ttotal: 38s\tremaining: 37.9s\n",
      "1200:\tlearn: 6.8592963\ttest: 12.6474755\tbest: 12.6221952 (740)\ttotal: 45.4s\tremaining: 30.2s\n",
      "1400:\tlearn: 6.6204551\ttest: 12.6708864\tbest: 12.6221952 (740)\ttotal: 52.7s\tremaining: 22.6s\n",
      "1600:\tlearn: 6.4117375\ttest: 12.6663840\tbest: 12.6221952 (740)\ttotal: 1m\tremaining: 15s\n",
      "1800:\tlearn: 6.2262361\ttest: 12.6908622\tbest: 12.6221952 (740)\ttotal: 1m 7s\tremaining: 7.44s\n",
      "1999:\tlearn: 6.0496056\ttest: 12.7047370\tbest: 12.6221952 (740)\ttotal: 1m 14s\tremaining: 0us\n",
      "\n",
      "bestTest = 12.62219525\n",
      "bestIteration = 740\n",
      "\n",
      "Shrink model to first 741 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x228d2c5cad0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fungsi untuk menghitung bobot agar model fokus pada nilai tinggi (TIDAK SEHAT)\n",
    "def calculate_weights(y):\n",
    "    # Memberikan bobot lebih tinggi jika PM > 80 (mendekati ambang batas TIDAK SEHAT)\n",
    "    weights = np.where(y > 80, 8.0, 1.0) \n",
    "    # Tambahan bobot ekstra untuk outlier ekstrem\n",
    "    weights = np.where(y > 120, 15.0, weights)\n",
    "    return weights\n",
    "\n",
    "weights_10 = calculate_weights(y_train_pm10)\n",
    "weights_25 = calculate_weights(y_train_pm25)\n",
    "\n",
    "reg_params = {\n",
    "    'iterations': 2000,\n",
    "    'learning_rate': 0.03,\n",
    "    'depth': 7,\n",
    "    'loss_function': 'MAE', # MAE lebih baik untuk menangkap fluktuasi dibanding RMSE\n",
    "    'random_seed': 42,\n",
    "    'verbose': 200\n",
    "}\n",
    "\n",
    "print(\"ðŸš€ Training PM10 Regressor with Heavy Weights...\")\n",
    "model_pm10 = CatBoostRegressor(**reg_params)\n",
    "model_pm10.fit(X_train, y_train_pm10, sample_weight=weights_10, eval_set=(X_test, y_test_pm10), cat_features=CAT_FEATURES)\n",
    "\n",
    "print(\"\\nðŸš€ Training PM2.5 Regressor with Heavy Weights...\")\n",
    "model_pm25 = CatBoostRegressor(**reg_params)\n",
    "model_pm25.fit(X_train, y_train_pm25, sample_weight=weights_25, eval_set=(X_test, y_test_pm25), cat_features=CAT_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbf69790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Threshold sensitif telah diatur, Master.\n"
     ]
    }
   ],
   "source": [
    "def get_ispu_category(pm10, pm25):\n",
    "    # Standar ISPU 2025: PM2.5 seringkali menjadi parameter kritis\n",
    "    # Kita turunkan sedikit batas deteksi agar model tidak bias ke SEDANG\n",
    "    \n",
    "    # Ambang batas deteksi TIDAK SEHAT (Disesuaikan agar lebih sensitif)\n",
    "    if pm25 >= 101 or pm10 >= 101: \n",
    "        return \"TIDAK SEHAT\"\n",
    "    elif pm25 >= 51 or pm10 >= 51:\n",
    "        return \"SEDANG\"\n",
    "    else:\n",
    "        return \"BAIK\"\n",
    "\n",
    "print(\"âœ“ Threshold sensitif telah diatur, Master.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72153509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Starting Recursive Regression Forecasting...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'pm_duakomalima_lag_7d'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 39\u001b[39m\n\u001b[32m     37\u001b[39m     \u001b[38;5;66;03m# Update fitur Delta yang baru kita buat\u001b[39;00m\n\u001b[32m     38\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m lag_dist == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m         feat_row[\u001b[33m'\u001b[39m\u001b[33mpm25_delta\u001b[39m\u001b[33m'\u001b[39m] = (res[\u001b[33m'\u001b[39m\u001b[33mpm25\u001b[39m\u001b[33m'\u001b[39m] * bias) - \u001b[43mfeat_row\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpm_duakomalima_lag_7d\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     40\u001b[39m         feat_row[\u001b[33m'\u001b[39m\u001b[33mpm10_delta\u001b[39m\u001b[33m'\u001b[39m] = (res[\u001b[33m'\u001b[39m\u001b[33mpm10\u001b[39m\u001b[33m'\u001b[39m] * bias) - feat_row[\u001b[33m'\u001b[39m\u001b[33mpm_sepuluh_lag_7d\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyError\u001b[39m: 'pm_duakomalima_lag_7d'"
     ]
    }
   ],
   "source": [
    "sample_sub = pd.read_csv(SAMPLE_SUB_PATH)\n",
    "sample_sub['tanggal'] = pd.to_datetime(sample_sub['id'].str.split('_').str[0])\n",
    "sample_sub['stasiun'] = sample_sub['id'].str.split('_').str[1]\n",
    "sample_sub = sample_sub.sort_values(['tanggal', 'stasiun'])\n",
    "\n",
    "# Median historis untuk filling cuaca\n",
    "df_stats = df.groupby(['stasiun', df['tanggal'].dt.month])[WEATHER_FEATURES + ROLLING_FEATURES].median()\n",
    "\n",
    "pm_values_dict = {} # Menyimpan (stasiun, tanggal) -> {'pm10': val, 'pm25': val}\n",
    "final_results = []\n",
    "\n",
    "print(\"ðŸ”„ Starting Recursive Regression Forecasting...\")\n",
    "\n",
    "for idx, row in sample_sub.iterrows():\n",
    "    st, dt, month = row['stasiun'], row['tanggal'], row['tanggal'].month\n",
    "    \n",
    "    # 1. Fill Features\n",
    "    feat_row = df_stats.loc[(st, month)].to_dict() if (st, month) in df_stats.index else df[WEATHER_FEATURES + ROLLING_FEATURES].median().to_dict()\n",
    "    feat_row.update({'year': dt.year, 'month': month, 'is_weekend': int(dt.dayofweek >= 5), 'is_holiday_nasional': 0, 'stasiun_encoded': le_stasiun.transform([st])[0]})\n",
    "    upward_noise = np.random.uniform(1.0, 1.25) # 100% - 125% dari nilai kemarin\n",
    "    yesterday_key = (st, dt - pd.Timedelta(days=1))\n",
    "    res_yesterday = pm_values_dict.get(yesterday_key, {'pm10': 45.0, 'pm25': 60.0})\n",
    "    feat_row[f'pm_duakomalima_lag_1d'] = res_yesterday['pm25'] * upward_noise\n",
    "    feat_row[f'pm_sepuluh_lag_1d'] = res_yesterday['pm10'] * upward_noise\n",
    "    \n",
    "    # 2. Dynamic Lags\n",
    "    for lag_dist, sfx in [(1, '1d'), (7, '7d')]:\n",
    "        target_date = dt - pd.Timedelta(days=lag_dist)\n",
    "        if (st, target_date) in pm_values_dict:\n",
    "            res = pm_values_dict[(st, target_date)]\n",
    "            # Master, di sini kita gunakan noise yang condong ke atas (1.0 sampai 1.3)\n",
    "            # agar polusi bisa merayap naik ke kategori TIDAK SEHAT\n",
    "            bias = np.random.uniform(0.98, 1.25) \n",
    "            feat_row[f'pm_sepuluh_lag_{sfx}'] = res['pm10'] * bias\n",
    "            feat_row[f'pm_duakomalima_lag_{sfx}'] = res['pm25'] * bias\n",
    "        else:\n",
    "            feat_row[f'pm_sepuluh_lag_{sfx}'] = 50.0\n",
    "            feat_row[f'pm_duakomalima_lag_{sfx}'] = 75.0\n",
    "    \n",
    "    # Calculate delta features after all lags are populated\n",
    "    feat_row['pm25_delta'] = feat_row.get('pm_duakomalima_lag_1d', 60.0) - feat_row.get('pm_duakomalima_lag_7d', 75.0)\n",
    "    feat_row['pm10_delta'] = feat_row.get('pm_sepuluh_lag_1d', 45.0) - feat_row.get('pm_sepuluh_lag_7d', 50.0)\n",
    "\n",
    "    # 3. Predict & Convert\n",
    "    input_df = pd.DataFrame([feat_row])[FEATURES]\n",
    "    p10_val = model_pm10.predict(input_df)[0]\n",
    "    p25_val = model_pm25.predict(input_df)[0]\n",
    "    \n",
    "    # Store numeric results for next lags\n",
    "    pm_values_dict[(st, dt)] = {'pm10': p10_val, 'pm25': p25_val}\n",
    "    \n",
    "    # Convert to Category\n",
    "    cat = get_ispu_category(p10_val, p25_val)\n",
    "    final_results.append({'id': row['id'], 'category': cat})\n",
    "\n",
    "# Save results\n",
    "submission_df = pd.DataFrame(final_results)\n",
    "submission_df.to_csv(\"submission_catboost_regression_stage2.csv\", index=False)\n",
    "print(\"âœ“ Submission saved: submission_catboost_regression_stage2.csv\")\n",
    "print(submission_df['category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b45d20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Regression Metrics for PM10:\n",
      "   - MAE  : 9.6518\n",
      "   - RMSE : 12.1876\n",
      "   - R2   : 0.5142\n",
      "\n",
      "ðŸ“Š Regression Metrics for PM2.5:\n",
      "   - MAE  : 12.6054\n",
      "   - RMSE : 16.2263\n",
      "   - R2   : 0.5666\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Prediksi angka PM pada data test\n",
    "pred_pm10 = model_pm10.predict(X_test)\n",
    "pred_pm25 = model_pm25.predict(X_test)\n",
    "\n",
    "def evaluate_regression(y_true, y_pred, name):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"ðŸ“Š Regression Metrics for {name}:\")\n",
    "    print(f\"   - MAE  : {mae:.4f}\")\n",
    "    print(f\"   - RMSE : {rmse:.4f}\")\n",
    "    print(f\"   - R2   : {r2:.4f}\\n\")\n",
    "\n",
    "evaluate_regression(y_test_pm10, pred_pm10, \"PM10\")\n",
    "evaluate_regression(y_test_pm25, pred_pm25, \"PM2.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb4e116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ Classification Performance (Converted from Regression):\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "          BAIK       0.71      0.32      0.45       213\n",
      "        SEDANG       0.74      0.94      0.83       849\n",
      "TIDAK ADA DATA       0.00      0.00      0.00        12\n",
      "   TIDAK SEHAT       0.42      0.12      0.19       141\n",
      "\n",
      "      accuracy                           0.73      1215\n",
      "     macro avg       0.47      0.35      0.37      1215\n",
      "  weighted avg       0.69      0.73      0.68      1215\n",
      "\n",
      "âœ… Final Weighted F1-Score: 0.6786\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. Konversi hasil prediksi angka ke kategori\n",
    "y_pred_cat = [get_ispu_category(p10, p25) for p10, p25 in zip(pred_pm10, pred_pm25)]\n",
    "\n",
    "# 2. Ambil kategori asli dari data test (asumsi kolom 'kategori' ada di df)\n",
    "y_true_cat = df[test_mask]['kategori'].values\n",
    "\n",
    "# 3. Print Classification Report\n",
    "print(\"ðŸŽ¯ Classification Performance (Converted from Regression):\")\n",
    "print(classification_report(y_true_cat, y_pred_cat))\n",
    "\n",
    "# 4. Print Specific F1-Score\n",
    "f1_weighted = f1_score(y_true_cat, y_pred_cat, average='weighted')\n",
    "print(f\"âœ… Final Weighted F1-Score: {f1_weighted:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
